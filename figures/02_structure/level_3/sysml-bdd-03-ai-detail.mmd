graph TB
    subgraph AIEngine["<<part def>> AI Engine"]
        subgraph STTBlock["<<part def>> STT Subsystem"]
            AudioProc["<<part>> Audio Processor<br/>16kHz sampling<br/>VAD detection"]
            WhisperModel["<<part>> Whisper Model<br/>Size: 1.55B params<br/>VRAM: 6GB<br/>Latency: 200-500ms"]
            AudioProc --> WhisperModel
        end
        
        subgraph LLMBlock["<<part def>> LLM Subsystem"]
            ContextMgr["<<part>> Context Manager<br/>Window: 8K tokens<br/>History: 20 turns"]
            LlamaModel["<<part>> Llama 3.1 8B<br/>Params: 8.03B<br/>VRAM: 16GB<br/>Latency: 400-600ms<br/>FLOPS: 32 TFLOPS"]
            ContextMgr --> LlamaModel
        end
        
        subgraph TTSBlock["<<part def>> TTS Subsystem"]
            ProsodyGen["<<part>> Prosody Generator<br/>Emotion markup"]
            PiperEngine["<<part>> Piper TTS<br/>Model: thorsten-low<br/>Size: 63MB<br/>Latency: 200-300ms"]
            ProsodyGen --> PiperEngine
        end
        
        STTBlock -->|text| LLMBlock
        LLMBlock -->|response| TTSBlock
    end
    
    subgraph Hardware["<<constraint def>> Hardware Requirements"]
        GPU["4×NVIDIA A100 (40GB)<br/>Total VRAM: 160GB<br/>Total FLOPS: 624 TFLOPS<br/><br/>Allocation:<br/>- GPU0: Whisper (6GB)<br/>- GPU1-3: Llama (48GB)<br/>- Spare: 106GB"]
        
        CPU["2×AMD EPYC 7543<br/>Cores: 64 (32×2)<br/>RAM: 512GB DDR4<br/>FLOPS: 5.12 TFLOPS"]
        
        Storage["NVMe: 4TB<br/>Models: 50GB<br/>Data: 200GB"]
    end
    
    AIEngine -.deployed on.-> GPU
    AIEngine -.deployed on.-> CPU
    AIEngine -.deployed on.-> Storage
    
    style AIEngine fill:#f3e5f5,stroke:#6a1b9a,stroke-width:4px
    style STTBlock fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style LLMBlock fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    style TTSBlock fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    style Hardware fill:#ffebee,stroke:#c62828,stroke-width:2px
