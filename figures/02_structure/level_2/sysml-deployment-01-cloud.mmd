graph TB
    subgraph CloudProvider["«executionEnvironment» Cloud Provider (Multi-Region)"]
        subgraph Region1["«node» Primary Region (eu-central-1)"]
            subgraph K8sCluster["«executionEnvironment» Kubernetes Cluster (3 AZs)"]
                subgraph IngressLayer["«node» Ingress Layer"]
                    LB["«artifact» Cloud Load Balancer<br/>TLS 1.3 termination<br/>DDoS protection"]
                    Ingress["«artifact» Nginx Ingress<br/>Rate limiting: 1000 req/s<br/>Cert-manager: Let's Encrypt"]
                end
                
                subgraph ComputeNodes["«node» Compute Nodes"]
                    subgraph CPUPods["CPU-based Pods"]
                        GatewayPod["«artifact» API Gateway<br/>Replicas: 3-10<br/>CPU: 2 vCPU, RAM: 4GB<br/>Image: gateway:v1.2.3"]
                        
                        ConvPod["«artifact» Conversation Service<br/>Replicas: 5-30<br/>CPU: 4 vCPU, RAM: 8GB<br/>Image: conversation:v2.1.0"]
                        
                        TTSPod["«artifact» TTS Service<br/>Replicas: 3-10<br/>CPU: 2 vCPU, RAM: 4GB<br/>Image: tts-piper:v1.0.5<br/>Model: thorsten-low (DE), amy-low (EN)"]
                        
                        UtilityPods["«artifact» Utility Services<br/>Session, User, Analytics, Scenario<br/>Replicas: 2-5 each<br/>CPU: 1-2 vCPU, RAM: 2-4GB"]
                    end
                    
                    subgraph GPUPods["GPU-accelerated Pods"]
                        STTPod["«artifact» STT Service<br/>Replicas: 3-10<br/>GPU: NVIDIA T4 (16GB)<br/>CPU: 4 vCPU, RAM: 16GB<br/>Image: stt-whisper:v3.0.0<br/>Model: Whisper Large v3<br/>Throughput: 100 req/s"]
                        
                        OptionalLLM["«artifact» Self-Hosted LLM (optional)<br/>Replicas: 2<br/>GPU: 2×A100 (80GB)<br/>CPU: 8 vCPU, RAM: 64GB<br/>Image: llama-3.1-70b:int8<br/>Latency: 1200-1800ms<br/>Cost savings: 40%"]
                    end
                end
                
                subgraph DataPlane["«node» Data Plane"]
                    PostgresPrimary["«artifact» PostgreSQL Primary<br/>Storage: 100GB SSD<br/>CPU: 4 vCPU, RAM: 16GB<br/>Version: 15.3<br/>Tables: users, sessions, conversations"]
                    
                    PostgresReplica1["«artifact» PostgreSQL Replica 1<br/>Read-only<br/>Lag: <1s"]
                    
                    PostgresReplica2["«artifact» PostgreSQL Replica 2<br/>Read-only<br/>Lag: <1s"]
                    
                    RedisCluster["«artifact» Redis Cluster<br/>Nodes: 6 (3 primary + 3 replica)<br/>Memory: 16GB per node (96GB total)<br/>Persistence: AOF<br/>Use: session cache, rate limits"]
                    
                    MilvusDB["«artifact» Milvus Vector DB<br/>Storage: 50GB SSD<br/>CPU: 4 vCPU, RAM: 16GB<br/>Vectors: 10M × 1536-dim<br/>Index: HNSW"]
                end
            end
            
            subgraph Observability["«node» Observability Stack"]
                Prometheus["«artifact» Prometheus<br/>Retention: 30 days<br/>Scrape: 15s interval<br/>Storage: 100GB"]
                
                Grafana["«artifact» Grafana<br/>Dashboards: 12<br/>Alerts: SEV1/SEV2/SEV3"]
                
                Jaeger["«artifact» Jaeger Tracing<br/>Sampling: 10%<br/>Retention: 7 days"]
            end
        end
        
        subgraph Region2["«node» Failover Region (eu-west-1)"]
            K8sFailover["«executionEnvironment» Kubernetes Cluster<br/>Standby mode<br/>RTO: 5 minutes<br/>RPO: 1 hour"]
            
            PostgresFailover["«artifact» PostgreSQL Replica<br/>Async replication<br/>Lag: <5 minutes"]
            
            RedisFailover["«artifact» Redis Replica<br/>Async replication"]
        end
        
        subgraph ExternalServices["«node» External Services"]
            CloudLLM["«service» Cloud LLM Provider<br/>Primary: GPT-4o (OpenAI)<br/>Fallback: Claude 3.5 Sonnet (Anthropic)<br/>Latency: 800-1200ms<br/>Cost: $0.0025/turn"]
            
            ObjectStorage["«service» Object Storage<br/>Audio archives: 5TB<br/>Backup snapshots: 2TB<br/>Retention: 12 months"]
            
            CDN["«service» CDN<br/>Static assets<br/>Edge locations: 50+"]
        end
    end
    
    %% Connections
    LB --> Ingress
    Ingress --> GatewayPod
    GatewayPod --> ConvPod
    GatewayPod --> UtilityPods
    ConvPod --> STTPod
    ConvPod --> CloudLLM
    ConvPod --> TTSPod
    ConvPod --> RedisCluster
    ConvPod --> PostgresPrimary
    ConvPod --> MilvusDB
    
    PostgresPrimary --> PostgresReplica1
    PostgresPrimary --> PostgresReplica2
    PostgresPrimary -.async replication.-> PostgresFailover
    RedisCluster -.async replication.-> RedisFailover
    
    GatewayPod -.metrics.-> Prometheus
    ConvPod -.metrics.-> Prometheus
    STTPod -.metrics.-> Prometheus
    TTSPod -.metrics.-> Prometheus
    Prometheus --> Grafana
    
    ConvPod -.traces.-> Jaeger
    GatewayPod -.traces.-> Jaeger
    
    PostgresPrimary -.backup.-> ObjectStorage
    RedisCluster -.backup.-> ObjectStorage
    MilvusDB -.backup.-> ObjectStorage
    
    Region1 -.failover trigger.-> K8sFailover
    
    style CloudProvider fill:#e3f2fd,stroke:#0d47a1,stroke-width:4px
    style Region1 fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px
    style Region2 fill:#fff3e0,stroke:#e65100,stroke-width:3px
    style K8sCluster fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    style IngressLayer fill:#ffebee,stroke:#b71c1c,stroke-width:2px
    style ComputeNodes fill:#e0f2f1,stroke:#004d40,stroke-width:2px
    style DataPlane fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    style Observability fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    style ExternalServices fill:#f1f8e9,stroke:#33691e,stroke-width:2px
