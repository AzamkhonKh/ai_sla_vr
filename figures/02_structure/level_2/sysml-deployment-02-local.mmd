graph TB
    subgraph OnPrem["On-Premises Infrastructure"]
        GPU["GPU Cluster<br/>8×H100 80GB<br/>640GB VRAM"]
        
        AI["AI Services<br/>LLM + STT + TTS<br/>2×A100 40GB"]
        
        Backend["Backend Services<br/>API + Database<br/>CPU Cluster"]
        
        Storage["Storage<br/>2TB NVMe<br/>Distributed"]
    end
    
    GPU --> AI
    AI --> Backend
    Backend --> Storage
    
    style GPU fill:#ffccbc
    style AI fill:#c8e6c9
    style Backend fill:#bbdefb
    style Storage fill:#fff9c4
